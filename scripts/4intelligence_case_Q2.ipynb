{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Case - 4Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model to Predict ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\gabriel\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\gabriel\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# installing libs and packages\r\n",
    "\r\n",
    "!pip install sklearn -q\r\n",
    "!pip install xgboost -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libs\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from numpy import mean, median\r\n",
    "from datetime import datetime , date\r\n",
    "import statsmodels.api as sm\r\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\r\n",
    "from sklearn.model_selection import train_test_split ,GridSearchCV\r\n",
    "from sklearn.linear_model import LinearRegression ,ElasticNet\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.metrics import *\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "from xgboost import XGBRegressor\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\r\n",
    "\r\n",
    "data_path = 'E:\\\\Projects\\\\4intelligence_case\\\\data\\\\Bases_Final_ADS_Jun2021.xlsx'\r\n",
    "df = pd.read_excel(data_path, sheet_name='dados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datetime to date\r\n",
    "df['data_tidy'] = df['data_tidy'].apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nan values to zero\r\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating year, month features\r\n",
    "\r\n",
    "df['ano'] = df['data_tidy'].apply(lambda x: x.year)\r\n",
    "df['mes'] = df['data_tidy'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new features\r\n",
    "\r\n",
    "# total energy consumed by business category\r\n",
    "df['com_total'] = df['com_co'] + df['com_n'] + df['com_ne'] + df['com_s'] + df['com_se']\r\n",
    "\r\n",
    "# total energy consumed by industrial category\r\n",
    "df['ind_total'] = df['ind_co'] + df['ind_n'] + df['ind_ne'] + df['ind_s'] + df['ind_se']\r\n",
    "\r\n",
    "# total energy consumed by residential category\r\n",
    "df['res_total'] = df['res_co'] + df['res_n'] + df['res_ne'] + df['res_s'] + df['res_se']\r\n",
    "\r\n",
    "# total energy consumed\r\n",
    "df['total'] = df['res_total'] + df['ind_total'] + df['com_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new features about each region\r\n",
    "# consumption total by region\r\n",
    "\r\n",
    "# SE\r\n",
    "df['se_total'] = df['com_se'] + df['ind_se'] + df['com_se']\r\n",
    "# S\r\n",
    "df['s_total'] = df['com_s'] + df['ind_s'] + df['com_s']\r\n",
    "# NE\r\n",
    "df['ne_total'] = df['com_ne'] + df['ind_ne'] + df['com_ne']\r\n",
    "# N\r\n",
    "df['n_total'] = df['com_n'] + df['ind_n'] + df['com_n']\r\n",
    "# CO\r\n",
    "df['co_total'] = df['com_co'] + df['ind_co'] + df['com_co']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new features about temperature\r\n",
    "\r\n",
    "# max tempearature in Brazil\r\n",
    "df['max_temp'] = df[['temp_max_n','temp_max_ne','temp_max_co','temp_max_se','temp_max_s']].max(axis =1)\r\n",
    "# min tempearature in Brazil\r\n",
    "df['min_temp'] = df[['temp_max_n','temp_max_ne','temp_max_co','temp_max_se','temp_max_s']].min(axis =1)\r\n",
    "# delta - the difference\r\n",
    "df['delta'] = df['max_temp'] - df['min_temp']\r\n",
    "# the mean -min-max\r\n",
    "df['media_temp'] = (df['max_temp'] + df['min_temp'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train dataset\r\n",
    "\r\n",
    "df_train = df.loc[df['data_tidy'] <= date(2021,2,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating correlation matrix\r\n",
    "mc = df_train.corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ind_se         1.000000\n",
       "ind_total      0.885493\n",
       "pim_se         0.793250\n",
       "ind_ne         0.754299\n",
       "pim_s          0.683477\n",
       "pim_ne         0.450059\n",
       "pim_n          0.316463\n",
       "se_total       0.313763\n",
       "pmc_a_co       0.301078\n",
       "ne_total       0.287529\n",
       "mes            0.281097\n",
       "pmc_a_ne       0.229778\n",
       "pmc_a_se       0.218574\n",
       "pmc_r_co       0.216244\n",
       "ind_s          0.201316\n",
       "delta          0.192139\n",
       "max_temp       0.181328\n",
       "temp_max_n     0.180960\n",
       "pmc_a_n        0.156524\n",
       "pmc_r_ne       0.130908\n",
       "temp_max_co    0.116144\n",
       "ind_n          0.104751\n",
       "pmc_a_s        0.102949\n",
       "pmc_r_n        0.067781\n",
       "total          0.060419\n",
       "pim_co         0.047890\n",
       "pmc_r_se       0.046026\n",
       "pop_ocup_br    0.044074\n",
       "du             0.036097\n",
       "temp_max_ne   -0.011721\n",
       "s_total       -0.019891\n",
       "n_total       -0.036934\n",
       "pmc_r_s       -0.059158\n",
       "temp_max_se   -0.076352\n",
       "com_se        -0.088309\n",
       "ind_co        -0.091900\n",
       "co_total      -0.108182\n",
       "media_temp    -0.110655\n",
       "com_co        -0.115085\n",
       "com_total     -0.123896\n",
       "res_se        -0.127810\n",
       "temp_min_ne   -0.130096\n",
       "temp_min_co   -0.132103\n",
       "com_n         -0.135607\n",
       "com_s         -0.143222\n",
       "temp_min_n    -0.152974\n",
       "min_temp      -0.164531\n",
       "temp_max_s    -0.171490\n",
       "com_ne        -0.187855\n",
       "res_total     -0.211206\n",
       "temp_min_s    -0.211779\n",
       "temp_min_se   -0.242553\n",
       "res_s         -0.245775\n",
       "res_co        -0.253246\n",
       "res_ne        -0.258035\n",
       "ano           -0.270593\n",
       "res_n         -0.276200\n",
       "renda_r       -0.296604\n",
       "massa_r       -0.334349\n",
       "Name: ind_se, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strongests correlations between industrial energy consumption SE\r\n",
    "mc['ind_se'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting features and target\r\n",
    "\r\n",
    "features = df_train[['pim_se','ind_ne','massa_r','renda_r']]\r\n",
    "\r\n",
    "label = df_train['ind_se'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalling features\r\n",
    "\r\n",
    "scaler = StandardScaler()\r\n",
    "features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the features\r\n",
    "\r\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features , label, \r\n",
    "                                                                            test_size = 0.25, \r\n",
    "                                                                            random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model 1: Linear Regression\r\n",
    "\r\n",
    "model1 = LinearRegression()\r\n",
    "model1.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\r\n",
    "\r\n",
    "predictions = model1.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MAE:  191.2077749368664\n",
      "Linear Regression MSE:  60394.7139623759\n",
      "Coefficient of determination: 0.72\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model 1\r\n",
    "\r\n",
    "mae = mean_absolute_error(test_labels , predictions)\r\n",
    "mse = mean_squared_error(test_labels , predictions)\r\n",
    "print('Linear Regression MAE: ', mae)\r\n",
    "print('Linear Regression MSE: ', mse)\r\n",
    "print('Coefficient of determination: %.2f'\r\n",
    "      % r2_score(test_labels , predictions))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1_ratio': 1, 'max_iter': 500}\n"
     ]
    }
   ],
   "source": [
    "# model 2: ElasticNet\r\n",
    "\r\n",
    "model2 = ElasticNet()\r\n",
    "\r\n",
    "# test all hyperparams below\r\n",
    "param_grid = [{'l1_ratio':[0.25, 0.5, 0.75, 1],\r\n",
    "               'max_iter':[500, 750, 1000, 2000, 5000]}]\r\n",
    "\r\n",
    "# exhaustive search for best params\r\n",
    "GS = GridSearchCV(model2 , param_grid , scoring= 'neg_mean_absolute_error' , error_score= 'raise', cv=5)\r\n",
    "GS.fit(train_features, train_labels)\r\n",
    "print(GS.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2 with best params\r\n",
    "\r\n",
    "model2 = ElasticNet(l1_ratio = GS.best_params_['l1_ratio'] , \r\n",
    "                    max_iter = GS.best_params_['max_iter'])\r\n",
    "\r\n",
    "model2.fit(train_features , train_labels)\r\n",
    "predictions = model2.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet MAE:  194.52254272095595\n",
      "ElasticNet MSE:  62915.55858418738\n",
      "Coefficient of determination: 0.71\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model 2\r\n",
    "\r\n",
    "mae = mean_absolute_error(test_labels , predictions)\r\n",
    "mse = mean_squared_error(test_labels , predictions)\r\n",
    "print('ElasticNet MAE: ', mae)\r\n",
    "print('ElasticNet MSE: ', mse)\r\n",
    "print('Coefficient of determination: %.2f'\r\n",
    "      % r2_score(test_labels , predictions))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# model 2: Random Forest\r\n",
    "\r\n",
    "model3 = RandomForestRegressor()\r\n",
    "\r\n",
    "# test all hyperparams below\r\n",
    "param_grid = [{'n_estimators':[35,40,45,50,55,60,70,80,90,100,150,180,220,250,280],\r\n",
    "               'max_depth':[3,5,6,7,8,9,10,11,12]}]\r\n",
    "\r\n",
    "# exhaustive search for best params\r\n",
    "GS = GridSearchCV(model3 , param_grid , scoring= 'neg_mean_absolute_error' , error_score= 'raise', cv=5)\r\n",
    "GS.fit(train_features, train_labels)\r\n",
    "print(GS.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 3 with best params\r\n",
    "\r\n",
    "model3 = RandomForestRegressor(n_estimators = GS.best_params_['n_estimators'] , \r\n",
    "                            max_depth = GS.best_params_['max_depth'])\r\n",
    "\r\n",
    "model3.fit(train_features , train_labels)\r\n",
    "predictions = model3.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAE:  211.37414761596972\n",
      "Random Forest MSE:  72349.94748516087\n",
      "Coefficient of determination: 0.67\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model 3\r\n",
    "\r\n",
    "mae = mean_absolute_error(test_labels , predictions)\r\n",
    "mse = mean_squared_error(test_labels , predictions)\r\n",
    "print('Random Forest MAE: ', mae)\r\n",
    "print('Random Forest MSE: ', mse)\r\n",
    "print('Coefficient of determination: %.2f'\r\n",
    "      % r2_score(test_labels , predictions))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'booster': 'gbtree', 'eval_metric': 'mae', 'learning_rate': 0.5, 'max_depth': 10, 'n_estimators': 150, 'objective': 'reg:squarederror'}\n"
     ]
    }
   ],
   "source": [
    "# model 4: Gradient descent\r\n",
    "\r\n",
    "model4 = XGBRegressor()\r\n",
    "\r\n",
    "# test all hyperparams below\r\n",
    "param_grid = [{'max_depth':[4,5,6,7,8,9,10,11,12,13],\r\n",
    "               'n_estimators':[150,180,200,220],\r\n",
    "               'objective':['reg:squarederror'],\r\n",
    "               'eval_metric':['mae'],\r\n",
    "               'booster':['gbtree'],\r\n",
    "               'learning_rate':[0.5,0.7,0.9]}]\r\n",
    "\r\n",
    "# exhaustive search for best params\r\n",
    "GS = GridSearchCV(model4 , param_grid , scoring= 'neg_mean_absolute_error' , error_score= 'raise', cv=5)\r\n",
    "GS.fit(train_features, train_labels)\r\n",
    "print(GS.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 4 with best params\r\n",
    "model4 = XGBRegressor(n_estimators = GS.best_params_['n_estimators'] , \r\n",
    "                    max_depth = GS.best_params_['max_depth'],\r\n",
    "                    objective = GS.best_params_['objective'],\r\n",
    "                    eval_metric = GS.best_params_['eval_metric'],\r\n",
    "                    booster = GS.best_params_['booster'],\r\n",
    "                    learning_rate = GS.best_params_['learning_rate'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c33996a1a7c5fda85612bd918562506cfff69a3497605696c7a2bee4a3573303"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}